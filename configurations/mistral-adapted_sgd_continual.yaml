cache_datasets: ""
output_dir: ""
model_name: ""
use_lora: false
# Template
response_template: "###Summary:"
prompt_template: "###Text:"
# Training Parameters
training_bs: 16
evaluate_bs: 16
num_train_epochs: 7
## Optimizer Parameters
weight_decay: 5e-3
learning_rate: 1e-5
lr_scheduler_type: "linear"
wermup_ratio: 0.3